## QUESTION 1.1
?coagulation
str(coagulation)
head(coagulation)
boxplot(coagulation$coag ~ coagulation$diet)
coagulation[which(coagulation$diet == "C"), ]
## QUESTION 1.2
lmCoag <- lm(coag ~ diet - 1, data = coagulation) # "-1" removes the intercept
summary(lmCoag)
coef(lmCoag)
meanA <- coef(lmCoag)[1]
meanB <- coef(lmCoag)[2]
meanC <- coef(lmCoag)[3]
meanD <- coef(lmCoag)[4]
scalediet <- summary(lmCoag)$sigma
scalediet
## QUESTION 1.3
AOVcoag <- aov(coagulation$coag ~ coagulation$diet)
summary(AOVcoag)  # significant difference between means because p-value <0.05
## QUESTION 1.4
leveneTest(coagulation$coag ~ coagulation$diet - 1) # homoskedasticity ok
qqnorm(lmCoag$residuals)
qqline(lmCoag$residuals)
shapiro.test(lmCoag$resid) # residuals ok
## QUESTION 1.5
wald.test(Sigma = vcov(lmCoag), b = coef(lmCoag), L = t(c(0, 1, -1, 0))) # not different
?wald
help('wald')
install.packages('aod')
## QUESTION 1.5
wald.test(Sigma = vcov(lmCoag), b = coef(lmCoag), L = t(c(0, 1, -1, 0))) # not different
help(wald.test)
help(aod)
install.packages('aod')
library(aod)
dev.off()
rm(list = ls())
library(aod)
library(car)
library(faraway)
library(MASS)
## QUESTION 1.1
?coagulation
str(coagulation)
head(coagulation)
boxplot(coagulation$coag ~ coagulation$diet)
coagulation[which(coagulation$diet == "C"), ]
## QUESTION 1.2
lmCoag <- lm(coag ~ diet - 1, data = coagulation) # "-1" removes the intercept
summary(lmCoag)
coef(lmCoag)
meanA <- coef(lmCoag)[1]
meanB <- coef(lmCoag)[2]
meanC <- coef(lmCoag)[3]
meanD <- coef(lmCoag)[4]
scalediet <- summary(lmCoag)$sigma
scalediet
## QUESTION 1.3
AOVcoag <- aov(coagulation$coag ~ coagulation$diet)
summary(AOVcoag)  # significant difference between means because p-value <0.05
## QUESTION 1.4
leveneTest(coagulation$coag ~ coagulation$diet - 1) # homoskedasticity ok
qqnorm(lmCoag$residuals)
qqline(lmCoag$residuals)
shapiro.test(lmCoag$resid) # residuals ok
## QUESTION 1.5
wald.test(Sigma = vcov(lmCoag), b = coef(lmCoag), L = t(c(0, 1, -1, 0))) # not different
t.test(x = coagulation$coag[which(coagulation$diet == "B")],
y = coagulation$coag[which(coagulation$diet == "C")],
var.equal = TRUE)
# Uncorrected CI:
diffAB <- meanB - meanA
nA <- length(which(coagulation$diet == "A"))
nB <- length(which(coagulation$diet == "B"))
diffAB + c(-1, 1) * qt(1 - 0.05/2, df = lmCoag$df) * scalediet * sqrt(1/nB + 1/nA)
# with Bonferroni correction: 4*3/2 = 6 possible tests:
diffAB + c(-1, 1) * qt(1 - 0.05/6, df = lmCoag$df) * scalediet * sqrt(1/nB + 1/nA)
# ScheffÃ©:
k <- 4 # = number of groups
critvalue <- sqrt((k-1) * qf(0.95, df1 = k - 1, df2 = lmCoag$df)) # = M in course notes
diffAB + c(-1, 1) * critvalue * scalediet * sqrt(1/nB + 1/nA)
# TukeyHSD
TukeyHSD(AOVcoag)
plot(TukeyHSD(AOVcoag))
## QUESTION 1.7
wald.test(b = coef(lmCoag), Sigma = vcov(lmCoag), L = t(c(1, 1, -1, -1)))
car2 <- read.table(file.choose(), header = TRUE, sep = ",")
car2 <- read.table(file.choose(), header = TRUE, sep = ",")
#car origin should be a qualitative variable
car2$origin <- factor(car2$origin)
str(car2)
#car origin should be a qualitative variable
car2$origin <- factor(car2$origin)
summary(car2)
## QUESTION 2.2
boxplot(car2$acceleration)
qqnorm(car2$acceleration)
qqline(car2$acceleration)
boxplot(car2$displacement, main = "displacement")
boxplot(car2$horsepower,   main = "horsepower")
boxplot(car2$weight,       main = "weight")
boxplot(car2$class,        main = "class")
pairs(car2)
## QUESTION 2.3
Mod1 <- lm(acceleration ~ ., data = car2)
summary(Mod1)
plot(Mod1)
stres1 <- stdres(Mod1)
qqnorm(stres1)
qqline(stres1)
shapiro.test(stres1)
plot(density(stres1))
## QUESTION 2.4
hist(car2$acceleration, breaks = sqrt(nrow(car2)))
plot(density(car2$acceleration))
shapiro.test(car2$acceleration)
boxcox(acceleration ~ ., data = car2)
car3 <- car2
car3$acceleration <- bcPower(car2$acceleration, lambda = -0.5)
plot(density(car3$acceleration))
shapiro.test(car3$acceleration)
Mod2 <- lm(acceleration ~ ., data = car3)
summary(Mod2)
plot(Mod2)
plot(density(stres2))
stres2 <- stdres(Mod2)
qqnorm(stres2)
qqline(stres2)
shapiro.test(stres2)
plot(density(stres2))
# Perform partial F-test on cylinders, model, origin and class
Mod3 <- lm(acceleration ~ displacement + horsepower + weight, data = car3)
anova(Mod3, Mod2)
stres3 <- stdres(Mod3)
qqnorm(stres3)
qqline(stres3)
shapiro.test(stres3)
plot(density(stres3))
?fpe
str(fpe)
pairs(fpe)
boxplot(fpe)
boxplot(fpe$F)
head(fpe)
# some observations might be outlying/influential. The sample with largest value for
# variable F (obs. 5) also distorts the relation with the other variables, so we remove it.
pairs(fpe[-5, ])
fpe <- fpe[-5, ]
## QUESTION 3.1
lmFpe <- lm(A2 ~ 0 + A + B + C + D + E + F + G + H + J + K + N , data = fpe)
## QUESTION 3.2
summary(lmFpe)
summary(lmFpe)$r.squared
cor(fpe[, -c(1, 13)])
## QUESTION 3.3
qqnorm(stdres(lmFpe))
qqline(stdres(lmFpe))
plot(lmFpe)
plot(fitted(lmFpe), lmFpe$resid^2)
plot(fpe$EI, abs(lmFpe$resid))
## QUESTION 3.4
plot(fpe$EI)
# heteroskedasticity could be caused by these different sizes
# => compensate this (e.g. by setting weights prop. to 1/EI.)
wi <- 1/fpe$EI
lmFpe2<-lm(A2 ~ A + B + C + D + E + F + G + H + J + K + N - 1, weights = wi, data = fpe)
summary(lmFpe2) # check the difference between the estimates and their SE.
# lm returns the unweighted residuals
reslm <- fpe$A2 - fitted(lmFpe2)
residuals(lmFpe2) - reslm
# lm.influence returns the weighted residuals
lm.influence(lmFpe2)$wt.res - residuals(lmFpe2)*sqrt(wi)
# also the functions stdres (from MASS) and rstandard (from stats package) use the
# weighted residuals (try: edit(lmwork) to check the code from stdres,
# and look at the help file of rstandard)
stdres(lmFpe2) - rstandard(lmFpe2)
# normality of weighted residuals
qqnorm( residuals(lmFpe2) * sqrt(wi) )
qqnorm(stdres(lmFpe2)) # to be preferred
# check heteroscedasticity again
plot(fitted(lmFpe2), lmFpe2$resid)
plot(fpe$EI, abs(lmFpe2$resid))
plot(lmFpe2$resid * sqrt(wi))
plot(fpe$A2, lmFpe2$resid * sqrt(wi))
install.packages(c("DAAG", "leaps", "rgl"))
print('hoi')
setwd("~/1_KUL/BME - 2e jaar/SEM2/SDA/Oefenzittingen/Ex7")
dev.off()
rm(list = ls())
library(DAAG)
library(leaps)
library(MASS)
cafe <- read.table("cafedata.txt", header = TRUE)
str(cafe)
head(cafe)
class(cafe$Day_of_Week)
acal <- cafe[1:30, ]     # calibration data
aval <- cafe[-c(1:30), ] # validation data
dim(acal) # 30 x 17
dim(aval) # 17 x 17
?regsubsets
?plot.regsubsets
salesall <- regsubsets(Sales ~ . , data = acal, nbest = 1, nvmax = 19)
## SUMMARY OF BEST MODELS
str(summary(salesall))
summary(salesall, matrix.logical = TRUE)
plot(salesall, scale = "r2")
## PLOT R2
summary(salesall)$which
numvar <- as.numeric(row.names(summary(salesall)$which))
numvar
rsq <- summary(salesall)$rsq
plot(numvar, rsq, pch = 16)
chosenR2 <- which.max(rsq)
chosenR2
## PLOT R2adjusted
adjrsq <- summary(salesall)$adjr2
plot(numvar, adjrsq, pch = 16)
chosenadjR2 <- which.max(adjrsq)
chosenadjR2
# model 13 gives best result
summary(salesall)$which[chosenadjR2, ]
max(adjrsq)
plot(salesall, scale = "adjr2")
## PLOT AIC
aic <- summary(salesall)$bic + (2 - log(nrow(acal))) * numvar # BIC => AIC conversion
plot(numvar, aic, pch = 16)
chosenaic <- which.min(aic)
chosenaic
#model 13 gives best result
summary(salesall)$which[chosenaic, ]
## PLOT Cp
cp <- summary(salesall)$cp
plot(numvar, cp, pch = 16)
chosencp <- which.min(cp)
chosencp
# model 5 gives best result
summary(salesall)$which[chosencp, ]
designcal <- model.matrix(lm(Sales ~ . , data = acal))
designval <- model.matrix(lm(Sales ~ . , data = aval))
## PRESS for best model according to R2
summary(salesall)$which[chosenR2, ]
selR2 <- names(which( summary(salesall)$which[chosenR2, !colnames(summary(salesall)$which) %in% c("(Intercept)")] == 1))
acal2 <- cbind(designcal[, selR2], acal[, "Sales", drop = FALSE])
aval2 <- cbind(designval[, selR2], aval[, "Sales", drop = FALSE])
mod2 <- lm(Sales ~ . , data = acal2)
cvpress2 <- press(mod2)
# or explicitly
X <- model.matrix(mod2)
cvpress2 <- sum( ( mod2$resid / (1 - diag( X%*% solve(crossprod(X))%*%t(X)) ) )^2 )
cvpress2
# CV-PRESS = 54603.62
mcvpress2 <- cvpress2/nrow(acal2)
mcvpress2
## MSEP on validation set
fittedval2 <- predict(mod2, newdata = aval2, interval = "prediction")[, 1]
sum((fittedval2-aval2$Sales)^2)/nrow(aval2)
## PRESS for best model according to adjR2
seladjR2 <- names(which(summary(salesall)$which[chosenadjR2, !colnames(summary(salesall)$which) %in% c("(Intercept)")] == 1))
acal3 <- cbind(designcal[, seladjR2], acal[, "Sales", drop = FALSE])
aval3 <- cbind(designval[, seladjR2], aval[, "Sales", drop = FALSE])
mod3 <- lm(Sales ~ . , data = acal3)
cvpress3 <- press(mod3)
cvpress3
# CV-PRESS = 21522.61
mcvpress3 <- cvpress3/nrow(acal3)
mcvpress3
## MSEP on validation set
fittedval3 <- predict(mod3, newdata = aval3, interval = "prediction")[, 1]
sum((fittedval3 - aval3$Sales)^2) / nrow(aval3)
## PRESS for best model according to AIC
selaic <- names(which(summary(salesall)$which[chosenaic, !colnames(summary(salesall)$which) %in% c("(Intercept)")] == 1))
acal4 <- cbind(designcal[, selaic], acal[, "Sales", drop = FALSE])
aval4 <- cbind(designval[, selaic], aval[, "Sales", drop = FALSE])
mod4 <- lm(Sales ~ . , data = acal4)
cvpress4 <- press(mod4)
cvpress4
# CV-PRESS = 21522.61
mcvpress4 <- cvpress4/nrow(acal4)
mcvpress4
## MSEP on validation set
fittedval4 = predict(mod4,newdata=aval4,interval="prediction")[, 1]
sum((fittedval4-aval4$Sales)^2)/nrow(aval4)
## PRESS for best model according to Cp.
selcp <- names(which(summary(salesall)$which[chosencp, !colnames(summary(salesall)$which) %in% c("(Intercept)")] == 1))
acal5 <- cbind(designcal[, selcp], acal[, "Sales", drop = FALSE])
aval5 <- cbind(designval[, selcp], aval[, "Sales", drop = FALSE])
mod5 <- lm(Sales ~ . , data = acal5)
cvpress5 <- press(mod5)
cvpress5
# CV-PRESS = 16149.82
mcvpress5 <- cvpress5/nrow(acal5)
mcvpress5
## MSEP on validation set
fittedval5 <- predict(mod5, newdata = aval5, interval = "prediction")[, 1]
sum((fittedval5 - aval5$Sales)^2) / nrow(aval5)
## START FROM FULL MODEL
mod6 <- lm(Sales ~ . , data = acal2)
## START FROM FULL MODEL
mod6 <- lm(Sales ~ . , data = acal2)
##  BACKWARDS
?stepAIC
modFB <- stepAIC(mod6, list(lower = ~ 1, upper = ~ .), direction = "back", k = 2)
summary(modFB)$coeff[, 1]
## STEPWISE
modFS = stepAIC(mod6, list(lower = ~ 1,upper = ~ .), direction = "both", k = 2)
summary(modFS)$coeff[, 1]
## START FROM EMPTY MODEL
mod7 <- lm(Sales ~ 1, data = acal2)
## CREATE FORMULA
listofvars <- colnames(designcal)
listofvars <- listofvars[2:length(listofvars)]  # remove intercept
fullformula <- as.formula(paste("~", paste(listofvars, collapse = "+")))
## FORWARDS
modEF <- stepAIC(mod7, list(lower = ~ 1, upper = fullformula), direction = "forward", k = 2)
summary(modEF)$coeff[, 1]
## STEPWISE
modES <- stepAIC(mod7, list(lower = ~ 1, upper = fullformula), direction = "both", k = 2)
summary(modES)$coeff[, 1]
predict(modES, newdata = aval2, interval = "prediction")
sum((predict(modES, newdata = aval2, interval = "prediction")[, 1] - aval2$Sales)^2) / nrow(aval)
library(cluster)
library(rgl)
## Read windsor
windsor <- read.table("windsor.txt", header = TRUE, quote = "\"")
dim(windsor)
head(windsor)
## (a) Scale variables
apply(windsor, 2, mean)
apply(windsor, 2, sd)
boxplot(windsor)
windsor <- scale(windsor, center = TRUE, scale = TRUE)
plot3d(windsor)
dev.off()
rm(list = ls())
library(car)
library(MASS)
library(pls)
library(robustbase)
library(rrcov)
library(SMPracticals)
install.packages('pls')
install.packages('SMPracticals')
rm(list = ls())
library(car)
library(MASS)
library(pls)
library(robustbase)
library(rrcov)
library(SMPracticals)
rm(list = ls())
library(car)
library(MASS)
library(pls)
library(robustbase)
library(rrcov)
library(SMPracticals)
setwd("~/1_KUL/BME - 2e jaar/SEM2/SDA/Oefenzittingen/Ex8")
rm(list = ls())
library(car)
library(MASS)
library(pls)
library(robustbase)
library(rrcov)
library(SMPracticals)
?pollution
data(pollution)
a1 <- pollution
dim(a1)
names(a1)
a2 <- pollution
a2$hc  <- log(a1$hc)
a2$nox <- log(a1$nox)
a2$so  <- log(a1$so)
head(a2)
## QUESTION 1.1
crm <- cor(a2[, -which(names(a2) == "mort")]) # = cor(a2[, -16])
## QUESTION 1.1
crm <- cor(a2[, -which(names(a2) == "mort")]) # = cor(a2[, -16])
crm
diag(solve(crm))       # VIF values
max(diag(solve(crm)))  # > 10: strong multicollinearity
mean(diag(solve(crm))) # >> 1: strong multicollinearity
ev <- eigen(crm)
ev$values / sum(ev$values)              # some small values: indication of multicollinearity
sqrt( max(ev$values) / min(ev$values) ) # < 30: no indication of strong multicollinearity
## QUESTION 1.2
a3 <- a2[1:50, ]
## PCA
resultpca <- PcaClassic(a3[, -which(names(a3)=="mort")], scale = TRUE)
screeplot(resultpca, type = "lines")
summary(resultpca)
## PCR
?pcr
resultpcr5 <- pcr(mort ~ ., data = a3, scale = TRUE, ncomp = 5)
coef(resultpcr5, intercept = TRUE)
## manually, check how we obtain these values
pcascores <- getScores(resultpca)
pcat <- pcascores[, 1:5]
coefpca <- coefficients(lm(mort ~ pcat-1, data = a3)) # alpha-hat, page 141
pcaloadings <- getLoadings(resultpca)
pcaloadings[, 1:5] %*% coefpca # beta-plus, last page 141
## LS on original variables: coefs are very different
resultlm <- lm(mort ~ ., data = a3)
summary(resultlm)
t(t(coef(resultlm)))
## choose number of components based on LOO-CV (= leave-one-out cross-validation).
resultpcrLOO <- pcr(mort ~ ., data = a3, scale = TRUE, validation = "LOO")
summary(resultpcrLOO)
coef(resultpcrLOO)
install.packages(c("pls", "SMPracticals"))
install.packages(c("pls", "SMPracticals"))
?RMSEP
rm(list = ls())
library(car)
library(MASS)
library(pls)
library(robustbase)
library(rrcov)
library(SMPracticals)
?pollution
data(pollution)
a1 <- pollution
dim(a1)
names(a1)
a2 <- pollution
a2$hc  <- log(a1$hc)
a2$nox <- log(a1$nox)
a2$so  <- log(a1$so)
head(a2)
## QUESTION 1.1
crm <- cor(a2[, -which(names(a2) == "mort")]) # = cor(a2[, -16])
crm
diag(solve(crm))       # VIF values
max(diag(solve(crm)))  # > 10: strong multicollinearity
mean(diag(solve(crm))) # >> 1: strong multicollinearity
ev <- eigen(crm)
ev$values / sum(ev$values)              # some small values: indication of multicollinearity
sqrt( max(ev$values) / min(ev$values) ) # < 30: no indication of strong multicollinearity
## QUESTION 1.2
a3 <- a2[1:50, ]
## PCA
resultpca <- PcaClassic(a3[, -which(names(a3)=="mort")], scale = TRUE)
screeplot(resultpca, type = "lines")
summary(resultpca)
## PCR
?pcr
resultpcr5 <- pcr(mort ~ ., data = a3, scale = TRUE, ncomp = 5)
coef(resultpcr5, intercept = TRUE)
## manually, check how we obtain these values
pcascores <- getScores(resultpca)
pcat <- pcascores[, 1:5]
coefpca <- coefficients(lm(mort ~ pcat-1, data = a3)) # alpha-hat, page 141
pcaloadings <- getLoadings(resultpca)
pcaloadings[, 1:5] %*% coefpca # beta-plus, last page 141
## LS on original variables: coefs are very different
resultlm <- lm(mort ~ ., data = a3)
summary(resultlm)
t(t(coef(resultlm)))
## choose number of components based on LOO-CV (= leave-one-out cross-validation).
resultpcrLOO <- pcr(mort ~ ., data = a3, scale = TRUE, validation = "LOO")
summary(resultpcrLOO)
coef(resultpcrLOO)
?RMSEP
plot(RMSEP(resultpcrLOO, estimate = "train"), main = "training RMSEP")
plot(RMSEP(resultpcrLOO, estimate = "CV"), main = "CV MSEP")
plot(RMSEP(resultpcrLOO, newdata = a2[51:60, ], estimate = "test"), main = "validation RMSEP")
plot(RMSEP(resultpcrLOO, estimate = "all", newdata = a2[51:60, ]))
# black curve corresponds with training
# red/green with CV and adjCV
# blue with validation set
validationplot(resultpcrLOO, val.type = "RMSEP", estimate = "all", newdata = a2[51:60, ])
lambdaR <- exp(seq(log(1/1000), 0, length.out = 100))
lambdaR
plot(lambdaR)
## ridge trace
result.ridge <- lm.ridge(mort ~ ., data = a3, lambda = lambdaR)
plot(result.ridge)
## mean VIF values
result <- rep(NA, length(lambdaR))
for (i in 1:length(lambdaR)){
d1 <- try(solve( crm + lambdaR[i] * diag(ncol(crm)) ))
if(is.numeric(d1)){
result[i] <- mean(diag(d1 %*% crm %*% d1))
}
}
plot(lambdaR, result)
abline(h = 1)
lambdaS <- lambdaR[which(result < 1)[1]]
lambdaS
result.ridgeS <- lm.ridge(mort ~ ., data = a3, lambda = lambdaS)
coef(result.ridgeS)
# RMSEP on validation set
Xr <- data.matrix(a2[51:60,!(names(a3)=="mort")])
dim(Xr)
sqrt(mean( (cbind(1, Xr) %*% coef(result.ridgeS) - a2$mort[51:60])^2 ))
?hills
?hills
## classical analysis
hills.lm <- lm(time ~ dist + climb, data = hills)
## classical analysis
hills.lm <- lm(time ~ dist + climb, data = hills)
## some residual plots
studr <- studres(hills.lm)
plot(fitted(hills.lm), studr, ylim = c(-2.5, 8))
abline(h = 2.5, lty = 2)
abline(h = -2.5, lty = 2)
# With the 'identify' command you can select data points on the plot and then the
# labels of the data points appear (these labels are stored in row.names(hills)).
# This allows you to identify the outlying data points. Click with the left mouse button
# next to the data points you want to identify. Stop by pressing Esc.
identify(fitted(hills.lm), studr, row.names(hills))
